{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating cassava disease detection using an SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and paths defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Imports and File Paths ---\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set file paths for the E8 Trial (Trial 3)\n",
    "UNINFECTED_PATH = 'data/TME204-Patch_E4_E6_E8_28DPI_Dataset/E8-TME204/E8_TME204_28dpi_Dec_16_2020/Uninfected/E8_TME204_28dpi_Dec_16_2020_Uninfected_11_06_23_33.mat'\n",
    "UCBSV_PATH = 'data/TME204-Patch_E4_E6_E8_28DPI_Dataset/E8-TME204/E8_TME204_28dpi_Dec_16_2020/UCBSV/E8_TME204_28dpi_Dec_16_2020_UCBSV_11_06_23_36.mat'\n",
    "\n",
    "print(\"Libraries imported and paths defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: data/TME204-Patch_E4_E6_E8_28DPI_Dataset/E8-TME204/E8_TME204_28dpi_Dec_16_2020/UCBSV/E8_TME204_28dpi_Dec_16_2020_UCBSV_11_06_23_36.mat\n",
      "\n",
      "--- Verification Successful ---\n",
      "Type of extracted data: <class 'numpy.ndarray'>\n",
      "Shape of extracted data: ()\n",
      "\n",
      "Mean values for the 9 patches of the first leaf:\n",
      "[[ 18.26475694  17.18098958  17.80555556  25.25694444  24.59548611\n",
      "   24.61458333  25.88975694  23.25651042  23.6171875   21.74262153\n",
      "   19.94270833  24.29123264  24.03776042 126.12022569]\n",
      " [ 19.30425347  18.21831597  18.87239583  25.87934028  25.06987847\n",
      "   25.06336806  26.22135417  23.58810764  24.19704861  22.32855903\n",
      "   20.63671875  24.69661458  24.30555556 123.49262153]\n",
      " [ 18.93142361  17.78862847  18.63888889  26.63758681  26.12847222\n",
      "   25.92491319  27.57161458  24.67751736  25.06857639  23.02039931\n",
      "   21.27647569  25.41840278  25.09635417 128.41710069]\n",
      " [ 16.72395833  16.09722222  15.64453125  20.52300347  19.93663194\n",
      "   20.49869792  21.06814236  18.90625     19.37717014  17.89973958\n",
      "   16.72048611  20.85373264  20.26085069 106.98828125]\n",
      " [ 18.67621528  18.68532986  19.13237847  25.98307292  25.1875\n",
      "   24.82248264  26.25086806  23.47699653  23.69618056  21.84418403\n",
      "   20.41796875  24.31423611  24.20572917 120.32074653]\n",
      " [ 18.82508681  17.59244792  17.87152778  24.93012153  24.17708333\n",
      "   24.50130208  25.55989583  23.13237847  23.56336806  21.69791667\n",
      "   20.08463542  24.49392361  24.21137153 125.03168403]\n",
      " [ 18.20008681  17.75260417  18.26996528  24.05989583  23.84765625\n",
      "   24.15538194  25.06467014  22.90407986  23.27170139  21.70269097\n",
      "   20.18272569  24.88845486  24.59809028 129.57421875]\n",
      " [ 16.92274306  16.75998264  17.00564236  24.66927083  23.74782986\n",
      "   23.11328125  24.92578125  21.68793403  22.49435764  20.47960069\n",
      "   19.01649306  22.43098958  22.06163194 109.07595486]\n",
      " [ 18.18315972  17.46484375  18.34114583  26.54600694  25.84635417\n",
      "   25.40060764  27.15190972  24.09895833  24.73350694  22.79817708\n",
      "   20.96440972  24.83159722  24.43706597 125.21831597]]\n"
     ]
    }
   ],
   "source": [
    "# --- Simple, Direct Test ---\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "\n",
    "# We will use the UCBSV file for this test as we have seen its structure in MATLAB\n",
    "UCBSV_PATH = 'data/TME204-Patch_E4_E6_E8_28DPI_Dataset/E8-TME204/E8_TME204_28dpi_Dec_16_2020/UCBSV/E8_TME204_28dpi_Dec_16_2020_UCBSV_11_06_23_36.mat'\n",
    "\n",
    "print(f\"Loading file: {UCBSV_PATH}\")\n",
    "\n",
    "# Load the data. squeeze_me=True simplifies the nested structure.\n",
    "mat_data = scipy.io.loadmat(UCBSV_PATH, squeeze_me=True)\n",
    "\n",
    "# The 'Patch' key contains an array of struct-like objects.\n",
    "# In this file, it's an array of 18 structs.\n",
    "all_scans = mat_data['Patch']\n",
    "\n",
    "# Access the first leaf scan's struct from the array\n",
    "first_scan_struct = all_scans[0]\n",
    "\n",
    "# From that single struct, access the 'mean_values' field.\n",
    "# This is the pre-calculated 9x14 matrix of features seen in MATLAB.\n",
    "mean_values_for_first_leaf = first_scan_struct['mean_values']\n",
    "\n",
    "print(\"\\n--- Verification Successful ---\")\n",
    "print(f\"Type of extracted data: {type(mean_values_for_first_leaf)}\")\n",
    "print(f\"Shape of extracted data: {mean_values_for_first_leaf.shape}\")\n",
    "print(\"\\nMean values for the 9 patches of the first leaf:\")\n",
    "print(mean_values_for_first_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/TME204-Patch_E4_E6_E8_28DPI_Dataset/E8-TME204/E8_TME204_28dpi_Dec_16_2020/UCBSV/E8_TME204_28dpi_Dec_16_2020_UCBSV_11_06_23_36.mat\n",
      "Successfully processed 162 patches from the UCBSV file.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Process the INFECTED (UCBSV) File ---\n",
    "print(f\"Processing file: {UCBSV_PATH}\")\n",
    "\n",
    "# Load the .mat file for the infected class. \n",
    "# 'squeeze_me=True' helps simplify the nested data structure loaded by scipy.\n",
    "mat_data_ucbsv = scipy.io.loadmat(UCBSV_PATH, squeeze_me=True)\n",
    "\n",
    "# Access the 'Patch' field, which contains an array of structs, one for each leaf scan.\n",
    "all_scans_ucbsv = mat_data_ucbsv['Patch']\n",
    "\n",
    "# Initialize a list to store the feature vectors for this class.\n",
    "ucbsv_features = []\n",
    "\n",
    "# Iterate through each leaf scan's struct.\n",
    "for scan_struct in all_scans_ucbsv:\n",
    "    # Extract the pre-calculated 'mean_values' from the struct.\n",
    "    # .item() is used to retrieve the numpy array from its 0-d container.\n",
    "    mean_vals_matrix = scan_struct['mean_values'].item()\n",
    "    \n",
    "    # The matrix is 9x14, where each row is a feature vector for one patch.\n",
    "    # Add all 9 feature vectors to the list for this class.\n",
    "    ucbsv_features.extend(mean_vals_matrix)\n",
    "\n",
    "# Print a confirmation with the total number of patches processed.\n",
    "print(f\"Successfully processed {len(ucbsv_features)} patches from the UCBSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/TME204-Patch_E4_E6_E8_28DPI_Dataset/E8-TME204/E8_TME204_28dpi_Dec_16_2020/Uninfected/E8_TME204_28dpi_Dec_16_2020_Uninfected_11_06_23_33.mat\n",
      "Successfully processed 162 patches from the Uninfected file.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Process the UNINFECTED File ---\n",
    "print(f\"Processing file: {UNINFECTED_PATH}\")\n",
    "\n",
    "# Load the .mat file for the uninfected class.\n",
    "mat_data_uninfected = scipy.io.loadmat(UNINFECTED_PATH, squeeze_me=True)\n",
    "\n",
    "# Access the 'Patch' field, containing an array of structs for each leaf scan.\n",
    "all_scans_uninfected = mat_data_uninfected['Patch']\n",
    "\n",
    "# Initialize a list to store the feature vectors for this class.\n",
    "uninfected_features = []\n",
    "\n",
    "# Iterate through each leaf scan's struct.\n",
    "for scan_struct in all_scans_uninfected:\n",
    "    # Extract the pre-calculated 'mean_values' from the struct.\n",
    "    # .item() is used to retrieve the numpy array from its 0-d container.\n",
    "    mean_vals_matrix = scan_struct['mean_values'].item()\n",
    "    \n",
    "    # The matrix is 9x14, where each row is a feature vector for one patch.\n",
    "    # Add all 9 feature vectors to the list for this class.\n",
    "    uninfected_features.extend(mean_vals_matrix)\n",
    "\n",
    "# Print a confirmation with the total number of patches processed.\n",
    "print(f\"Successfully processed {len(uninfected_features)} patches from the Uninfected file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete.\n",
      "Final feature matrix X shape: (324, 14)\n",
      "Final label vector y shape: (324,)\n",
      "\n",
      "--- Final Dataset Head ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_395</th>\n",
       "      <th>wl_415</th>\n",
       "      <th>wl_470</th>\n",
       "      <th>wl_528</th>\n",
       "      <th>wl_532</th>\n",
       "      <th>wl_550</th>\n",
       "      <th>wl_570</th>\n",
       "      <th>wl_585</th>\n",
       "      <th>wl_590</th>\n",
       "      <th>wl_610</th>\n",
       "      <th>wl_625</th>\n",
       "      <th>wl_640</th>\n",
       "      <th>wl_660</th>\n",
       "      <th>wl_880</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.703559</td>\n",
       "      <td>18.059462</td>\n",
       "      <td>16.894531</td>\n",
       "      <td>27.229601</td>\n",
       "      <td>26.131076</td>\n",
       "      <td>24.549045</td>\n",
       "      <td>28.139323</td>\n",
       "      <td>24.205295</td>\n",
       "      <td>25.448785</td>\n",
       "      <td>22.825955</td>\n",
       "      <td>20.521267</td>\n",
       "      <td>22.292969</td>\n",
       "      <td>21.752170</td>\n",
       "      <td>107.310764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.602865</td>\n",
       "      <td>16.409722</td>\n",
       "      <td>15.253038</td>\n",
       "      <td>25.079427</td>\n",
       "      <td>24.518229</td>\n",
       "      <td>22.747396</td>\n",
       "      <td>26.451389</td>\n",
       "      <td>23.542969</td>\n",
       "      <td>24.570312</td>\n",
       "      <td>22.351997</td>\n",
       "      <td>19.956597</td>\n",
       "      <td>20.965278</td>\n",
       "      <td>20.433160</td>\n",
       "      <td>92.058160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.036892</td>\n",
       "      <td>16.857639</td>\n",
       "      <td>15.898438</td>\n",
       "      <td>25.563368</td>\n",
       "      <td>24.887587</td>\n",
       "      <td>23.215712</td>\n",
       "      <td>26.603299</td>\n",
       "      <td>23.303819</td>\n",
       "      <td>24.248264</td>\n",
       "      <td>21.845920</td>\n",
       "      <td>19.694010</td>\n",
       "      <td>21.176649</td>\n",
       "      <td>20.752170</td>\n",
       "      <td>96.516059</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.746962</td>\n",
       "      <td>17.976128</td>\n",
       "      <td>17.099826</td>\n",
       "      <td>27.790365</td>\n",
       "      <td>26.640191</td>\n",
       "      <td>24.930122</td>\n",
       "      <td>28.705295</td>\n",
       "      <td>24.440104</td>\n",
       "      <td>25.649306</td>\n",
       "      <td>22.872396</td>\n",
       "      <td>20.459201</td>\n",
       "      <td>22.441406</td>\n",
       "      <td>22.033420</td>\n",
       "      <td>110.956163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.998264</td>\n",
       "      <td>17.991319</td>\n",
       "      <td>16.598958</td>\n",
       "      <td>26.419271</td>\n",
       "      <td>25.569010</td>\n",
       "      <td>24.216146</td>\n",
       "      <td>27.644097</td>\n",
       "      <td>25.355903</td>\n",
       "      <td>25.124566</td>\n",
       "      <td>22.956597</td>\n",
       "      <td>20.721354</td>\n",
       "      <td>22.669705</td>\n",
       "      <td>22.957899</td>\n",
       "      <td>110.958333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      wl_395     wl_415     wl_470     wl_528     wl_532     wl_550  \\\n",
       "0  19.703559  18.059462  16.894531  27.229601  26.131076  24.549045   \n",
       "1  17.602865  16.409722  15.253038  25.079427  24.518229  22.747396   \n",
       "2  18.036892  16.857639  15.898438  25.563368  24.887587  23.215712   \n",
       "3  19.746962  17.976128  17.099826  27.790365  26.640191  24.930122   \n",
       "4  18.998264  17.991319  16.598958  26.419271  25.569010  24.216146   \n",
       "\n",
       "      wl_570     wl_585     wl_590     wl_610     wl_625     wl_640  \\\n",
       "0  28.139323  24.205295  25.448785  22.825955  20.521267  22.292969   \n",
       "1  26.451389  23.542969  24.570312  22.351997  19.956597  20.965278   \n",
       "2  26.603299  23.303819  24.248264  21.845920  19.694010  21.176649   \n",
       "3  28.705295  24.440104  25.649306  22.872396  20.459201  22.441406   \n",
       "4  27.644097  25.355903  25.124566  22.956597  20.721354  22.669705   \n",
       "\n",
       "      wl_660      wl_880  label  \n",
       "0  21.752170  107.310764      0  \n",
       "1  20.433160   92.058160      0  \n",
       "2  20.752170   96.516059      0  \n",
       "3  22.033420  110.956163      0  \n",
       "4  22.957899  110.958333      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Dataset Tail ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wl_395</th>\n",
       "      <th>wl_415</th>\n",
       "      <th>wl_470</th>\n",
       "      <th>wl_528</th>\n",
       "      <th>wl_532</th>\n",
       "      <th>wl_550</th>\n",
       "      <th>wl_570</th>\n",
       "      <th>wl_585</th>\n",
       "      <th>wl_590</th>\n",
       "      <th>wl_610</th>\n",
       "      <th>wl_625</th>\n",
       "      <th>wl_640</th>\n",
       "      <th>wl_660</th>\n",
       "      <th>wl_880</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>18.399414</td>\n",
       "      <td>17.708984</td>\n",
       "      <td>17.836914</td>\n",
       "      <td>25.652344</td>\n",
       "      <td>25.061523</td>\n",
       "      <td>24.613281</td>\n",
       "      <td>26.552734</td>\n",
       "      <td>24.635742</td>\n",
       "      <td>24.850586</td>\n",
       "      <td>23.331055</td>\n",
       "      <td>21.224609</td>\n",
       "      <td>23.934570</td>\n",
       "      <td>23.666016</td>\n",
       "      <td>110.960938</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>16.695312</td>\n",
       "      <td>16.180664</td>\n",
       "      <td>16.449219</td>\n",
       "      <td>23.918945</td>\n",
       "      <td>23.214844</td>\n",
       "      <td>22.682617</td>\n",
       "      <td>24.471680</td>\n",
       "      <td>21.979492</td>\n",
       "      <td>22.477539</td>\n",
       "      <td>20.779297</td>\n",
       "      <td>19.007812</td>\n",
       "      <td>21.821289</td>\n",
       "      <td>21.415039</td>\n",
       "      <td>101.840820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>17.804688</td>\n",
       "      <td>16.208008</td>\n",
       "      <td>17.116211</td>\n",
       "      <td>23.941406</td>\n",
       "      <td>23.110352</td>\n",
       "      <td>23.979492</td>\n",
       "      <td>24.686523</td>\n",
       "      <td>24.301758</td>\n",
       "      <td>22.676758</td>\n",
       "      <td>21.613281</td>\n",
       "      <td>19.517578</td>\n",
       "      <td>24.284180</td>\n",
       "      <td>25.083984</td>\n",
       "      <td>136.611328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>18.318359</td>\n",
       "      <td>16.760742</td>\n",
       "      <td>17.037109</td>\n",
       "      <td>23.227539</td>\n",
       "      <td>22.474609</td>\n",
       "      <td>23.113281</td>\n",
       "      <td>23.661133</td>\n",
       "      <td>22.624023</td>\n",
       "      <td>21.751953</td>\n",
       "      <td>20.505859</td>\n",
       "      <td>18.880859</td>\n",
       "      <td>22.994141</td>\n",
       "      <td>23.229492</td>\n",
       "      <td>118.534180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>18.838867</td>\n",
       "      <td>16.842773</td>\n",
       "      <td>16.708008</td>\n",
       "      <td>23.207031</td>\n",
       "      <td>22.743164</td>\n",
       "      <td>22.996094</td>\n",
       "      <td>23.920898</td>\n",
       "      <td>21.993164</td>\n",
       "      <td>22.583984</td>\n",
       "      <td>20.851562</td>\n",
       "      <td>19.057617</td>\n",
       "      <td>22.569336</td>\n",
       "      <td>22.363281</td>\n",
       "      <td>110.278320</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wl_395     wl_415     wl_470     wl_528     wl_532     wl_550  \\\n",
       "319  18.399414  17.708984  17.836914  25.652344  25.061523  24.613281   \n",
       "320  16.695312  16.180664  16.449219  23.918945  23.214844  22.682617   \n",
       "321  17.804688  16.208008  17.116211  23.941406  23.110352  23.979492   \n",
       "322  18.318359  16.760742  17.037109  23.227539  22.474609  23.113281   \n",
       "323  18.838867  16.842773  16.708008  23.207031  22.743164  22.996094   \n",
       "\n",
       "        wl_570     wl_585     wl_590     wl_610     wl_625     wl_640  \\\n",
       "319  26.552734  24.635742  24.850586  23.331055  21.224609  23.934570   \n",
       "320  24.471680  21.979492  22.477539  20.779297  19.007812  21.821289   \n",
       "321  24.686523  24.301758  22.676758  21.613281  19.517578  24.284180   \n",
       "322  23.661133  22.624023  21.751953  20.505859  18.880859  22.994141   \n",
       "323  23.920898  21.993164  22.583984  20.851562  19.057617  22.569336   \n",
       "\n",
       "        wl_660      wl_880  label  \n",
       "319  23.666016  110.960938      1  \n",
       "320  21.415039  101.840820      1  \n",
       "321  25.083984  136.611328      1  \n",
       "322  23.229492  118.534180      1  \n",
       "323  22.363281  110.278320      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 4: Combine Data and Finalize ---\n",
    "\n",
    "# Create numerical labels for each class (0 for uninfected, 1 for infected).\n",
    "uninfected_labels = [0] * len(uninfected_features)\n",
    "ucbsv_labels = [1] * len(ucbsv_features)\n",
    "\n",
    "# Combine the features and labels from both files into final numpy arrays.\n",
    "X = np.array(uninfected_features + ucbsv_features)\n",
    "y = np.array(uninfected_labels + ucbsv_labels)\n",
    "\n",
    "# Print the final shapes to confirm the dataset is correctly assembled.\n",
    "print(f\"\\nProcessing complete.\")\n",
    "print(f\"Final feature matrix X shape: {X.shape}\")\n",
    "print(f\"Final label vector y shape: {y.shape}\")\n",
    "\n",
    "# For easier inspection, create a pandas DataFrame.\n",
    "# Define column names based on the wavelengths from the research paper.\n",
    "wavelengths = [395, 415, 470, 528, 532, 550, 570, 585, 590, 610, 625, 640, 660, 880]\n",
    "columns = [f'wl_{wl}' for wl in wavelengths]\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "df['label'] = y\n",
    "\n",
    "# Display the top and bottom of the final DataFrame to verify its contents.\n",
    "print(\"\\n--- Final Dataset Head ---\")\n",
    "display(df.head())\n",
    "print(\"\\n--- Final Dataset Tail ---\")\n",
    "display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled successfully.\n",
      "Groups array created with shape: (324,). Unique groups: 36\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Prepare Data for SVM (Scaling & Grouping) ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1. Scale the features\n",
    "# StandardScaler transforms the data to have a mean of 0 and standard deviation of 1.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 2. Create the 'groups' array for Leave-One-Leaf-Out Cross-Validation\n",
    "# We have 18 uninfected scans and 18 infected scans, each with 9 patches.\n",
    "num_leaves_per_class = 18\n",
    "num_patches_per_leaf = 9\n",
    "num_total_leaves = num_leaves_per_class * 2 # 36 total leaves\n",
    "\n",
    "# Create an array where each patch is assigned a group ID (0 to 35) corresponding to its leaf.\n",
    "# e.g., [0,0,0,0,0,0,0,0,0, 1,1,1,..., 35,35,35]\n",
    "groups = np.repeat(np.arange(num_total_leaves), num_patches_per_leaf)\n",
    "\n",
    "print(\"Features scaled successfully.\")\n",
    "print(f\"Groups array created with shape: {groups.shape}. Unique groups: {len(np.unique(groups))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search with Leave-One-Group-Out Cross-Validation...\n",
      "Grid Search complete.\n",
      "\n",
      "--- Results ---\n",
      "Best Parameters Found: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 87.35%\n",
      "\n",
      "Target accuracy from paper: 90.8 ± 11.3%\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Setup and Run SVM with Grid Search Cross-Validation ---\n",
    "\n",
    "# 1. Define the parameter grid for the SVM\n",
    "# These are the hyperparameters we want to test.\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100], \n",
    "    'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['rbf'] # Using the Radial Basis Function kernel\n",
    "}\n",
    "\n",
    "# 2. Define the cross-validation strategy\n",
    "# LeaveOneGroupOut() will perform the \"leave-one-leaf-out\" evaluation from the paper.\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# 3. Create the GridSearchCV object\n",
    "# This will test all hyperparameter combinations using our specific cross-validation strategy.\n",
    "# 'n_jobs=-1' uses all available CPU cores to speed up the process.\n",
    "svm_grid_search = GridSearchCV(\n",
    "    estimator=SVC(), \n",
    "    param_grid=param_grid, \n",
    "    cv=logo, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4. Run the Grid Search\n",
    "# training 36 different models for each hyperparameter combination.\n",
    "print(\"Starting Grid Search with Leave-One-Group-Out Cross-Validation...\")\n",
    "svm_grid_search.fit(X_scaled, y, groups=groups)\n",
    "print(\"Grid Search complete.\")\n",
    "\n",
    "# 5. Display the results\n",
    "print(\"\\n--- Results ---\")\n",
    "print(f\"Best Parameters Found: {svm_grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Accuracy: {svm_grid_search.best_score_ * 100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTarget accuracy from paper: 90.8 ± 11.3%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Worst Performer Analysis ---\n",
      "Worst Cross-Validation Accuracy: 57.10%\n",
      "Parameters for Worst Performer: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Analyze the Worst Performing Model ---\n",
    "\n",
    "# The results for all runs are stored in the .cv_results_ attribute\n",
    "cv_results = svm_grid_search.cv_results_\n",
    "\n",
    "# Find the index (position) of the combination with the lowest average score\n",
    "worst_score_index = np.argmin(cv_results['mean_test_score'])\n",
    "\n",
    "# Use that index to get the worst score and the parameters that caused it\n",
    "worst_accuracy = cv_results['mean_test_score'][worst_score_index]\n",
    "worst_parameters = cv_results['params'][worst_score_index]\n",
    "\n",
    "print(\"--- Worst Performer Analysis ---\")\n",
    "print(f\"Worst Cross-Validation Accuracy: {worst_accuracy * 100:.2f}%\")\n",
    "print(f\"Parameters for Worst Performer: {worst_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Experiments: Performing cross trials of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_and_prepare_data(base_path, trial_name, class_name, date_folder, file_id):\n",
    "    \"\"\"\n",
    "    Loads and prepares spectral data from a single .mat file.\n",
    "\n",
    "    Args:\n",
    "        base_path (str): The root path to the dataset (e.g., 'data/').\n",
    "        trial_name (str): The trial identifier (e.g., 'E8-TME204').\n",
    "        class_name (str): The class folder ('Uninfected' or 'UCBSV').\n",
    "        date_folder (str): The specific date folder for the trial.\n",
    "        file_id (str): The unique identifier part of the .mat file name.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - np.array: A NumPy array of the feature vectors.\n",
    "            - int: The number of leaves (scans) found in the file.\n",
    "    \"\"\"\n",
    "    # --- THIS IS THE CORRECTED PART ---\n",
    "    # Construct the filename and then the full path\n",
    "    file_name = f\"{trial_name.split('-')[0]}_TME204_28dpi_{date_folder.split('_')[-1]}_{file_id}.mat\"\n",
    "    full_path = os.path.join(base_path, trial_name, date_folder, class_name, file_name)\n",
    "    \n",
    "    # Load the .mat file\n",
    "    mat_data = scipy.io.loadmat(full_path, squeeze_me=True)\n",
    "    \n",
    "    # Extract the 'Patch' data\n",
    "    all_scans = mat_data['Patch']\n",
    "    \n",
    "    # Handle case where there's only one scan\n",
    "    if all_scans.ndim == 0:\n",
    "        all_scans = [all_scans]\n",
    "        \n",
    "    num_leaves = len(all_scans)\n",
    "    \n",
    "    # Extract mean values from each scan\n",
    "    features = []\n",
    "    for scan_struct in all_scans:\n",
    "        mean_vals_matrix = scan_struct['mean_values'].item()\n",
    "        features.extend(mean_vals_matrix)\n",
    "        \n",
    "    return np.array(features), num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Dataset Paths ---\n",
    "\n",
    "BASE_DATA_PATH = 'data/TME204-Patch_E4_E6_E8_28DPI_Dataset/'\n",
    "\n",
    "# E4 Trial Details\n",
    "E4_TRIAL = 'E4-TME204'\n",
    "E4_DATE = 'E4_TME204_28dpi_Mar_5_2020'\n",
    "E4_UNINFECTED_ID = 'Uninfected_11_06_23_18'\n",
    "E4_UCBSV_ID = 'UCBSV_11_06_23_21'\n",
    "\n",
    "# E6 Trial Details\n",
    "E6_TRIAL = 'E6-TME204'\n",
    "E6_DATE = 'E6_TME204_28dpi_Jul_29_2020'\n",
    "E6_UNINFECTED_ID = 'Uninfected_11_06_23_29'\n",
    "E6_UCBSV_ID = 'UCBSV_11_06_23_24'\n",
    "\n",
    "# E8 Trial Details\n",
    "E8_TRIAL = 'E8-TME204'\n",
    "E8_DATE = 'E8_TME204_28dpi_Dec_16_2020'\n",
    "E8_UNINFECTED_ID = 'Uninfected_11_06_23_33'\n",
    "E8_UCBSV_ID = 'UCBSV_11_06_23_36'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Train on E8, test on E6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load E8 Training Data ---\n",
    "e8_uninfected_features, _ = load_and_prepare_data(BASE_DATA_PATH, E8_TRIAL, 'Uninfected', E8_DATE, E8_UNINFECTED_ID)\n",
    "e8_ucbsv_features, _ = load_and_prepare_data(BASE_DATA_PATH, E8_TRIAL, 'UCBSV', E8_DATE, E8_UCBSV_ID)\n",
    "\n",
    "# Create labels (0 for uninfected, 1 for infected)\n",
    "y_train_e8 = np.concatenate([np.zeros(len(e8_uninfected_features)), np.ones(len(e8_ucbsv_features))])\n",
    "X_train_e8 = np.concatenate([e8_uninfected_features, e8_ucbsv_features])\n",
    "\n",
    "print(f\"Training data (E8) loaded. X shape: {X_train_e8.shape}, y shape: {y_train_e8.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load E6 Testing Data ---\n",
    "e6_uninfected_features, num_uninfected_leaves_e6 = load_and_prepare_data(BASE_DATA_PATH, E6_TRIAL, 'Uninfected', E6_DATE, E6_UNINFECTED_ID)\n",
    "e6_ucbsv_features, num_ucbsv_leaves_e6 = load_and_prepare_data(BASE_DATA_PATH, E6_TRIAL, 'UCBSV', E6_DATE, E6_UCBSV_ID)\n",
    "\n",
    "# Create labels\n",
    "y_test_e6 = np.concatenate([np.zeros(len(e6_uninfected_features)), np.ones(len(e6_ucbsv_features))])\n",
    "X_test_e6 = np.concatenate([e6_uninfected_features, e6_ucbsv_features])\n",
    "\n",
    "print(f\"Testing data (E6) loaded. X shape: {X_test_e6.shape}, y shape: {y_test_e6.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Train and Evaluate ---\n",
    "\n",
    "# 1. Scale the data (fit on training data, transform both)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_e8)\n",
    "X_test_scaled = scaler.transform(X_test_e6)\n",
    "\n",
    "# 2. Train the SVM using the best parameters from your previous work\n",
    "svm = SVC(C=100, gamma=0.01, kernel='rbf')\n",
    "svm.fit(X_train_scaled, y_train_e8)\n",
    "\n",
    "# 3. Predict on the patch level\n",
    "y_pred_patch = svm.predict(X_test_scaled)\n",
    "patch_accuracy = accuracy_score(y_test_e6, y_pred_patch)\n",
    "print(f\"--- Results: Train E8 / Test E6 ---\")\n",
    "print(f\"Overall Patch-Based Accuracy: {patch_accuracy * 100:.2f}%\")\n",
    "\n",
    "# 4. Implement and evaluate using Majority Voting per leaf\n",
    "num_patches_per_leaf = 9\n",
    "y_pred_leaf = []\n",
    "y_true_leaf = []\n",
    "\n",
    "# Process Uninfected Leaves\n",
    "for i in range(num_uninfected_leaves_e6):\n",
    "    start = i * num_patches_per_leaf\n",
    "    end = start + num_patches_per_leaf\n",
    "    patch_predictions = y_pred_patch[start:end]\n",
    "    # Predict for the leaf based on the mode of its patch predictions\n",
    "    y_pred_leaf.append(np.bincount(patch_predictions.astype(int)).argmax())\n",
    "    y_true_leaf.append(0) # True label is Uninfected\n",
    "\n",
    "# Process Infected Leaves\n",
    "offset = len(e6_uninfected_features)\n",
    "for i in range(num_ucbsv_leaves_e6):\n",
    "    start = offset + (i * num_patches_per_leaf)\n",
    "    end = start + num_patches_per_leaf\n",
    "    patch_predictions = y_pred_patch[start:end]\n",
    "    y_pred_leaf.append(np.bincount(patch_predictions.astype(int)).argmax())\n",
    "    y_true_leaf.append(1) # True label is Infected\n",
    "    \n",
    "leaf_accuracy = accuracy_score(y_true_leaf, y_pred_leaf)\n",
    "print(f\"Leaf-Based Accuracy (Majority Vote): {leaf_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassavaVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
